 â€” RAG-para-IA---Test (versiÃ³n final y completa)

# ğŸ§  RAG para IA â€” Sistema Local Completo

> *Un entorno 100% local para hacer preguntas a tus propios documentos usando inteligencia artificial. Sin nube. Sin APIs externas. Solo tu CPU y tu conocimiento.*

Este repositorio implementa un **sistema RAG (Retrieval-Augmented Generation) completo y autocontenido**, capaz de:
1. **Indexar** documentos (TXT, PDF, CSV) en una base vectorial.
2. **Responder preguntas** usando un modelo de lenguaje pequeÃ±o pero eficiente (**Qwen2 0.5B**) ejecutado localmente con `llama.cpp`.

âœ… Todo corre en tu PC.  
âœ… Tus datos nunca salen de tu mÃ¡quina.  
âœ… Funciona en espaÃ±ol gracias a embeddings multilingÃ¼es.

---

## ğŸ“¦ Â¿QuÃ© hace cada script?

| Archivo | FunciÃ³n |
|--------|--------|
| `preparar_rag.py` | Carga tus documentos, los divide en fragmentos y genera una base vectorial FAISS. |
| `rag_qwen2_completo.py` | Usa esa base + un modelo LLM local para responder preguntas sobre tus documentos. |

Juntos forman un **flujo RAG completo**: desde la ingesta hasta la respuesta.

---

## ğŸ› ï¸ Requisitos previos

- Python 3.9+
- ~2â€“4 GB de RAM libre (dependiendo del modelo)
- Windows, Linux o macOS
- ConexiÃ³n a internet **solo para la instalaciÃ³n inicial**

---

## â–¶ï¸ Pasos para usar el sistema

### 1. Clonar el repositorio
```bash
git clone https://github.com/maxiducoli/RAG-para-IA---Test.git
cd RAG-para-IA---Test

2. Instalar dependencias
bash
1
pipÂ installÂ langchainÂ langchain-communityÂ langchain-huggingfaceÂ faiss-cpuÂ pypdfÂ sentence-transformersÂ llama-cpp-python

ğŸ’¡ En Windows, si falla faiss-cpu, usÃ¡:

bash
1
pipÂ installÂ faiss-cpuÂ --extra-index-urlÂ https://download.pytorch.org/whl/cpu

3. Descargar el modelo LLM (Qwen2 0.5B)
Ve a: https://huggingface.co/Qwen/Qwen2-0.5B-Instruct-GGUF
DescargÃ¡ el archivo: qwen2-0_5b-instruct-fp16.gguf
Colocalo en la raÃ­z del proyecto (misma carpeta que los scripts).
âš ï¸ El modelo pesa ~1 GB. Asegurate de tener espacio.

4. Agregar tus documentos
Crea la carpeta documentos/ y colocÃ¡ dentro tus archivos:

.txt
.pdf
.csv
Ejemplo:

1234
documentos/â”œâ”€â”€Â manual_cocina.pdfâ”œâ”€â”€Â apuntes_programacion.txtâ””â”€â”€Â contactos.csv

5. Indexar tu conocimiento
bash
1
pythonÂ preparar_rag.py

Esto generarÃ¡ la carpeta vectorstore/ con tu base de conocimiento indexada.

âœ… VerÃ¡s mensajes como:
ğŸ“ Cargando documentos... â†’ ğŸ§  Generando embeddings... â†’ ğŸ‰ Â¡Datos preparados correctamente!

6. Hacer una consulta
EditÃ¡ el archivo rag_qwen2_completo.py y modificÃ¡ esta lÃ­nea:

python
1
preguntaÂ =Â "Â¿CÃ³moÂ desactivoÂ laÂ alarmaÂ deÂ miÂ cocina?"

Luego ejecutÃ¡:

bash
1
pythonÂ rag_qwen2_completo.py

VerÃ¡s algo como:

1234
ğŸ”Â Consulta:Â Â¿CÃ³moÂ desactivoÂ laÂ alarmaÂ deÂ miÂ cocina?ğŸ¤–Â Respuesta:ParaÂ desactivarÂ laÂ alarma,Â presionÃ¡Â elÂ botÃ³nÂ "Silenciar"Â duranteÂ 3Â segundos...

ğŸ” Â¿CÃ³mo funciona por dentro?
RecuperaciÃ³n:
Tu pregunta se convierte en un vector.
Se busca el fragmento mÃ¡s similar en vectorstore/.
GeneraciÃ³n:
Ese fragmento + tu pregunta se envÃ­an al modelo Qwen2.
El modelo genera una respuesta coherente y contextualizada.
El prompt estÃ¡ optimizado para evitar alucinaciones: si no hay contexto relevante, el modelo responde que no puede ayudar.

ğŸŒ Soporte multilingÃ¼e
Embeddings: usa sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 â†’ funciona bien en espaÃ±ol, inglÃ©s, portuguÃ©s, etc.
Modelo LLM: Qwen2 entiende instrucciones en mÃºltiples idiomas.
âš™ï¸ PersonalizaciÃ³n
MÃ¡s contexto: cambia k=1 a k=2 o k=3 en:
python
1
retrieverÂ =Â vectorstore.as_retriever(search_kwargs={"k":Â 1})

Modelo mÃ¡s potente: reemplazÃ¡ el .gguf por otro (ej: phi-3-mini, mistral-7b) si tenÃ©s mÃ¡s RAM.
Interfaz interactiva: podÃ©s convertir el script en un chat con input() o integrarlo a una web con Flask/FastAPI.
ğŸ”’ Privacidad
âœ… No se envÃ­a nada a la nube.
âœ… Todo se procesa localmente.
âœ… Ideal para documentos personales, tÃ©cnicos o confidenciales.
ğŸ“ Nota del autor
"No quiero una IA que sepa de todoâ€¦ quiero una que sepa de lo mÃ­o."
â€” Maximiliano Ducoli

Este proyecto nace de la necesidad de controlar el conocimiento que usa la IA. Porque a veces, lo mÃ¡s valioso no estÃ¡ en internetâ€¦ sino en tus propios archivos.

ğŸ“œ Licencia
Uso libre para fines personales, educativos o experimentales.
Si te sirve como base, Â¡adelante! Solo citÃ¡ la fuente.

